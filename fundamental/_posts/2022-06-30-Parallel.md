---
layout: post
title: "[CS]병렬 프로그래밍(1. 기초)"

category: study
sitemap: false
hide_last_modified: true
---
이번 Kore2022 competition에 참여하면서 다양한 강화학습 라이브러리에서 병렬 프로그래밍을 접하게 되었다. 특히 머신러닝 분야들 중에서도 강화학습은 시뮬레이터 구동을 위한 CPU의 사용률이 높기 때문에 분산처리/병렬처리가 필수적이다. 오늘은 기초적인 병렬 프로그래밍 개념과 예시들에 대해 포스팅한다.


# 병렬 프로그래밍
병렬 프로그래밍은 작업을 분할하여 더 짧은 시간에 문제를 해결하기 위해 일련의 리소스를 사용하는 방법이다. 

## Amdahl의 법칙
1. 컴퓨터 프로그램의 일부를 n개의 프로세서를 위해 병렬화 하였을 때 전체적으로 얼마만큼의 최대 성능 향상이 있는지 계산하는 데 사용되는 법칙  
      - 순차 프로그램에 비해 병렬 프로그램이 몇 배 빨라졌는지를 가늠한다.
2. 다른 오버헤드를 생각하지 않은 이상적인 경우를 가정한다.  
- 공식  
    p : 병렬화 된 부분이 순차 실행에서 차지한 비율  
    1 - p : 병렬화 되지 않은 부분이 순차 실행에서 차지한 비율  
    n : 프로세서의 개수  
    $$speedup = \frac{1}{(1-p + \frac{p}{n})}$$

    - 순차 실행시간의 60%를 차지하는 부분을 4개의 프로세서를 사용해서 병렬화 했다고 가정시 실행성능 182% 증가.
    $$ \frac{1}{(1-0.6) + \frac{0.6}{4}} = 1.82$$
    - 프로그램을 병렬화 했을 때의 speedup은 프로그램 내에서 병렬화 할 수 없는 부분이 차지하는 실행시간에 의해 주된 영향을 받는다.


## 병렬 프로그래밍 구현 순서
1. 병렬화할 부분을 찾아낸다.
2. 병렬화할 부분을 별도 함수로 분리한다.
3. 별도의 쓰레드/프로세스를 생성하여 실행할 함수를 연결한다.
4. 동기화가 필요하면 동기화 기능을 구현한다.

### 동기화
-  쓰레드의 실행순서를 정의하고, 이 순서에 반드시 따르도록 하는 것.  
- 한 순간에 하나의 쓰레드만 접근하게끔 하는것.

동기화 기법의 종류
1. 크리티컬 섹션 기반의 동기화
    - 화장실에 들어가기 전 열쇠로 문을 열고 들어가고, 나와서는 다른 사람을 위해 화장실 앞에 열쇠를 둔다.
    - 열쇠를 만들고, 획득, 돌려놓는 행위를 구현한 뒤, 리소스를 반환
2. 인터락 함수 기반의 동기화
    - 내부적으로 한 순간에 하나의 쓰레드에 의해서만 실행되도록 동기화 되어있음.
    - 이런 함수를 이용해 동기화 구현
3. 뮤텍스 기반의 동기화
    - 크리티컬 섹션 기반과 유사하며 더 간단한 커널기반 동기화
4. 이벤트 기반의 동기화


## 병렬 프로그래밍의 종류
1. 공유 메모리 병렬 프로그래밍 모델(ex. OpenMP)
2. 메시지 패싱 병렬 프로그래밍 모델(ex. MPI)
3. 가속기 프로그래밍 모델(ex. CUDA)


## OpenMP
- 일반적으로 Window나 Linux에서의 병렬처리는 마스터 스레드가 자식스레드를 생성하고 자식 스레드 모두가 작업이 끝나면 마스터 스레드가 종료시키는 방식이다.
그러나 OpenMP는 마스터스레드 자신도 자식스레드에 할당된 작업을 같이하고 작업이 끝나면 종료시킨다.
- OpenMP는 Fork-Join 모델을 이용하여 병렬화를 수행한다.
    - Fork-Join 모델 : Fork 단계에서 스레드를 생성하고, Join 단계에서 소멸
    - Fork에서 Join에 이르기까지 복수의 스레드가 동작하는 구간을 병렬영역이라고 한다. #pragma omp parallel 지시어를 만나게 되면, 마스터 스레드는 'Fork'를 수행하고 작업이 종료되면 'Join'을 수행하여 자식 스레드를 소멸시킨다.

## 병렬 프로그래밍 예시 OpenMP
```
//순차프로그래밍
#include <stdio.h>

#define N 20

int main(){
    int i, tid = 0;
    int istart = 0, iend = N;

    for(i=istart; i<iend; i++){
        printf("Hello CFD %d %d\n", tid, i);
    }
    return 0;
}
```

```
//OpenMP
#include <stdio.h>
#include <omp.h>
#defome N 20

int main()
{
    int i, tid, istart, iend;

    opm_set_num_threads(4);
#pragma omp parallel private(i, tid, istart, iend)
{
    tid = omp_get_thread_num();

    istart = tid * N/4;
    iend = (tid+1) * N/4;

    for(i=istart; i<iend; i++)
        printf("Hello CFD %d %d\n", tid, i);
}
return 0;
}
```

## 병렬프로그래밍 예시 - MPI
- CPU 간 통신을 지원하고 주소, 데이터 형 정의, 포맷정의 등이 필요한 고급언어

- 예시 : 적분식
$\int_0^1\frac{4}{1+x^2} dx = \pi $  
    - $\pi \approx \sum^n_{i=0}\frac{4}{1 + ((i-0.5)\times\frac{1}{n})^2} \times \frac{1}{n}$ 

```
#include <stdio.h>
#include <math.h>
#include <mpi.h>

#define SCOPE 100000000

int main(int argc, char *argv[])
{
    int i, n = SCOPE;
    double sum, step, pi, x, tsum, ROOT = 0;
    int nRank, nProcs;
    MPI_Status status;

    MPI_Init(&argc, &argv); // MPI 시스템 시작
    MPI_Comm_size(MPI_COMM_WORLD, &nProcs);  
    MPI_Comm_rank(MPI_COMM_WORLD, &nRank);

    if(nRank == ROOT){
        for (i = 1; i < nProcs; i++){
            MPI_Send(&n, 1, MPI_INT, i, 55, MPI_COMM_WORLD);
        }
    } // Root 프로세스는 특정 노드에게 덧셈을 위한 초기값등을 보내준다.
    else
        MPI_Recv(&n, 1, MPI_INT, ROOT, 55, MPI_COMM_WORLD, &status);

    step = 1.0/(double)n;
    sum = 0.0;
    tsum = 0.0;

    for(i = nRank; i < n ; i+= nProcs){
        x = ((double)i-0.5)*step;
        sum = sum + 4/(1.0 + x*x);
    } // 각 프로세스에서 계산을 수행한다.

    if(nRank == ROOT){
        // 합치고 결과값을 출력한다.
        tsum = sum;
        for(i=1; i<nProcs;i++){
            MPI_Recv(&sum, 1, MPI_DOUBLE, i, 56, MPI_COMM_WORLD, &status);
            tsum = tsum + sum;
        } 
        
        pi = step * tsum

        printf("---------------------------- \n");
        printf("PI = %.15f(Error = %E)\n", pi, fabs(acos(-1.0)- pi))
        printf("---------------------------- \n");
    }
    else    
        MPI_Send(&sum, 1, MPI_DOUBLE, ROOT, 56, MPI_COMM_WORLD);
    MPI_Finalize(); // MPI end

return 0;
}
```

### 기초 6개의 함수
- MPI_Init : MPI 시스템이 필요한 기본 셋업을 구축한다. 메시지 버퍼를 위한 저장공간 확보, 어떤 프로세스가 어떤 랭크를 가질지 결정 등
- MPI_Finalize : MPI 시스템에서 사용한 리소스들 해제
- MPI_COMM_WORLD : 서로 메시지를 전송하는 프로세스들의 집합을 나타내는 핸들  
    커뮤니케이터를 공유하는 프로세스들끼리 통신 가능
- MPI_Comm_rank(MPI_COMM_WORLD, &nRank) : 변수 nRank 에 커뮤니케이터에 있는 프로세스의 랭크를 리턴한다. (0~n-1까지)
- MPI_Comm_size(MPI_COMM_WORLD, &nProcs) : 변수 nProcs에 커뮤니케이터에 있는 프로세스의 수를 리턴한다.

- MPI_Send(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
    - buf : 송신버퍼의 시작주소
    - count : 송신될 원소 갯수
    - datatype : 각 원소의 MPI 데이터 타입(핸들)
    - dest : 수신 프로세스의 랭크
    - tag : 메시지 꼬리표
    - comm : MPI 커뮤니케이터(핸들)  
    - MPI_Send(&n, 1, MPI_INT, i, 55, MPI_COMM_WORLD)  

- MPI_Recv(void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)
    - buf : 수신버퍼의 시작주소
    - count : 수신될 원소 갯수
    - datatype : 각 원소의 MPI 데이터 타입(핸들)
    - dest : 송신 프로세스의 랭크
    - tag : 메시지 꼬리표
    - comm : MPI 커뮤니케이터(핸들)  
    - MPI_Recv(&n, 1, MPI_INT, ROOT, 55, MPI_COMM_WORLD, &status);



## 가속기(GPU 등) 아키텍처와 프로그래밍 모델
- NVIDIA, Intel, AMD, ...
- CUDA, OpenCL, OpenACC 등


참고자료 :  
http://ap2.khu.ac.kr/download/mpi_lec.pdf  
https://junstar92.tistory.com/220  
<OpenMP 병렬 프로그래밍> 정영훈 저  
EDISON Repository 유튜브